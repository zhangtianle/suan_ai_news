#!/usr/bin/env python3
"""
æ¯æ—¥åˆ†ææŠ¥å‘Šç”Ÿæˆå™¨
ä¸‹åˆ5ç‚¹æ‰§è¡Œï¼Œç”Ÿæˆ500å­—æ‘˜è¦å’Œ2000å­—è¯¦ç»†åˆ†æ
"""

import json
import os
from datetime import datetime
from pathlib import Path
from collections import defaultdict

PROJECT_ROOT = Path("/home/admin/.openclaw/workspace/tech-news")
PROCESSED_DIR = PROJECT_ROOT / "data" / "processed"
OUTPUT_DIR = PROJECT_ROOT / "output"

def load_processed_data():
    """åŠ è½½å¤„ç†åçš„æ•°æ®"""
    today = datetime.now().strftime("%Y-%m-%d")
    file_path = PROCESSED_DIR / f"processed_{today}.json"
    
    if not file_path.exists():
        # å°è¯•åŠ è½½æœ€è¿‘çš„æ•°æ®
        files = sorted(PROCESSED_DIR.glob("processed_*.json"), reverse=True)
        if files:
            file_path = files[0]
    
    if file_path.exists():
        with open(file_path, "r", encoding="utf-8") as f:
            return json.load(f)
    
    return None

def generate_summary(data):
    """ç”Ÿæˆ500å­—æ‘˜è¦"""
    date = data.get("date", datetime.now().strftime("%Y-%m-%d"))
    total = data.get("total_articles", 0)
    categories = data.get("categories", {})
    top_articles = data.get("top_articles", [])[:10]
    
    summary = f"""# ç§‘æŠ€èµ„è®¯æ—¥æŠ¥ - {date}

## ğŸ“Š ä»Šæ—¥æ¦‚è§ˆ
- **æ€»èµ„è®¯æ•°**: {total} æ¡
- **ä¸»è¦åˆ†ç±»**: {', '.join([f"{k}({v}æ¡)" for k, v in list(categories.items())[:5]])}

## ğŸ”¥ çƒ­ç‚¹èšç„¦
"""
    
    for i, article in enumerate(top_articles[:5], 1):
        title = article.get("title", "")[:50]
        source = article.get("source", "")
        summary += f"{i}. **{title}** - {source}\n"
    
    summary += """
## ğŸ’¡ ä»Šæ—¥è¦ç‚¹
"""
    
    # æŒ‰åˆ†ç±»æå–è¦ç‚¹
    categorized = data.get("categorized_articles", {})
    
    # AI ç›¸å…³
    ai_articles = categorized.get("AI", [])[:3]
    if ai_articles:
        summary += "\n### ğŸ¤– AI/å¤§æ¨¡å‹\n"
        for a in ai_articles:
            summary += f"- {a.get('title', '')[:60]}\n"
    
    # èŠ¯ç‰‡ç›¸å…³
    chip_articles = categorized.get("èŠ¯ç‰‡", [])[:3]
    if chip_articles:
        summary += "\n### ğŸ’» èŠ¯ç‰‡/ç®—åŠ›\n"
        for a in chip_articles:
            summary += f"- {a.get('title', '')[:60]}\n"
    
    # äº’è”ç½‘ç›¸å…³
    internet_articles = categorized.get("äº’è”ç½‘", [])[:3]
    if internet_articles:
        summary += "\n### ğŸŒ äº’è”ç½‘\n"
        for a in internet_articles:
            summary += f"- {a.get('title', '')[:60]}\n"
    
    summary += f"""

---
*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}*
"""
    
    return summary

def generate_detailed_report(data):
    """ç”Ÿæˆ2000å­—è¯¦ç»†æŠ¥å‘Š"""
    date = data.get("date", datetime.now().strftime("%Y-%m-%d"))
    total = data.get("total_articles", 0)
    categories = data.get("categories", {})
    top_articles = data.get("top_articles", [])
    categorized = data.get("categorized_articles", {})
    
    report = f"""# ç§‘æŠ€èµ„è®¯æ·±åº¦åˆ†ææŠ¥å‘Š
## {date}

---

## ä¸€ã€ä»Šæ—¥æ•°æ®æ¦‚è§ˆ

æœ¬æ—¥å…±æ”¶é›†ç§‘æŠ€èµ„è®¯ **{total}** æ¡ï¼Œæ¥æºæ¶µç›–å›½å†…å¤–ä¸»æµç§‘æŠ€åª’ä½“ã€‚

### åˆ†ç±»åˆ†å¸ƒ
"""
    
    for cat, count in sorted(categories.items(), key=lambda x: x[1], reverse=True):
        percentage = (count / total * 100) if total > 0 else 0
        report += f"- **{cat}**: {count} æ¡ ({percentage:.1f}%)\n"
    
    report += """

---

## äºŒã€é‡ç‚¹æ–°é—»æ·±åº¦è§£è¯»

"""
    
    # è¯¦ç»†åˆ†æå‰10æ¡
    for i, article in enumerate(top_articles[:10], 1):
        title = article.get("title", "æœªçŸ¥æ ‡é¢˜")
        source = article.get("source", "æœªçŸ¥æ¥æº")
        url = article.get("url", "")
        score = article.get("importance_score", 0)
        cats = article.get("auto_categories", [])
        
        report += f"""### {i}. {title}

**æ¥æº**: {source}  
**åˆ†ç±»**: {', '.join(cats)}  
**é‡è¦æ€§**: {'â­' * min(score, 5)}  
**é“¾æ¥**: {url}

"""
        
        # æ·»åŠ ç®€è¦åˆ†æ
        if "å‘å¸ƒ" in title or "æ¨å‡º" in title:
            report += "> ğŸ“¢ **äº§å“å‘å¸ƒåŠ¨æ€** - å€¼å¾—å…³æ³¨çš„æ–°äº§å“/æ–°åŠŸèƒ½å‘å¸ƒ\n\n"
        elif "èèµ„" in title or "æŠ•èµ„" in title:
            report += "> ğŸ’° **èµ„æœ¬åŠ¨æ€** - è¡Œä¸šèµ„æœ¬æµå‘å€¼å¾—å…³æ³¨\n\n"
        elif "çªç ´" in title or "é¦–æ¬¡" in title:
            report += "> ğŸš€ **æŠ€æœ¯çªç ´** - è¡Œä¸šé‡Œç¨‹ç¢‘äº‹ä»¶\n\n"
        
        report += "---\n\n"
    
    # åˆ†ç±»æ·±åº¦åˆ†æ
    report += """## ä¸‰ã€è¡Œä¸šè¶‹åŠ¿åˆ†æ

"""
    
    # AIæ¿å—
    ai_articles = categorized.get("AI", [])
    if ai_articles:
        report += f"""### ğŸ¤– AI/å¤§æ¨¡å‹æ¿å— ({len(ai_articles)}æ¡)

æœ¬æ—¥AIç›¸å…³èµ„è®¯å…±{len(ai_articles)}æ¡ï¼Œä¸»è¦æ¶‰åŠï¼š

"""
        for a in ai_articles[:8]:
            report += f"- {a.get('title', '')}\n"
        
        report += """
**è¶‹åŠ¿æ´å¯Ÿ**: """
        
        # ç®€å•è¶‹åŠ¿åˆ¤æ–­
        ai_titles = " ".join([a.get("title", "") for a in ai_articles])
        if "å¼€æº" in ai_titles:
            report += "å¼€æºæ¨¡å‹æŒç»­æ´»è·ƒï¼Œç¤¾åŒºç”Ÿæ€ç¹è£å‘å±•ã€‚"
        if "Agent" in ai_titles or "æ™ºèƒ½ä½“" in ai_titles:
            report += "AI Agentæˆä¸ºæ–°çš„ç«äº‰ç„¦ç‚¹ï¼Œå„å¤§å‚å•†åŠ é€Ÿå¸ƒå±€ã€‚"
        if "å¤šæ¨¡æ€" in ai_titles:
            report += "å¤šæ¨¡æ€æŠ€æœ¯å¿«é€Ÿæ¼”è¿›ï¼Œåº”ç”¨åœºæ™¯ä¸æ–­æ‹“å±•ã€‚"
        
        report += "\n\n"
    
    # èŠ¯ç‰‡æ¿å—
    chip_articles = categorized.get("èŠ¯ç‰‡", [])
    if chip_articles:
        report += f"""### ğŸ’» èŠ¯ç‰‡/ç®—åŠ›æ¿å— ({len(chip_articles)}æ¡)

"""
        for a in chip_articles[:5]:
            report += f"- {a.get('title', '')}\n"
        report += "\n"
    
    # äº’è”ç½‘æ¿å—
    internet_articles = categorized.get("äº’è”ç½‘", [])
    if internet_articles:
        report += f"""### ğŸŒ äº’è”ç½‘/å·¨å¤´æ¿å— ({len(internet_articles)}æ¡)

"""
        for a in internet_articles[:5]:
            report += f"- {a.get('title', '')}\n"
        report += "\n"
    
    # æŠ•èµ„æ¿å—
    invest_articles = categorized.get("åˆ›ä¸šæŠ•èµ„", [])
    if invest_articles:
        report += f"""### ğŸ’µ æŠ•èµ„/èèµ„æ¿å— ({len(invest_articles)}æ¡)

"""
        for a in invest_articles[:5]:
            report += f"- {a.get('title', '')}\n"
        report += "\n"
    
    report += f"""---

## å››ã€æ˜æ—¥å…³æ³¨ç‚¹

åŸºäºä»Šæ—¥æ•°æ®åˆ†æï¼Œå»ºè®®å…³æ³¨ä»¥ä¸‹æ–¹å‘ï¼š

1. **å¤§æ¨¡å‹ç«äº‰æ ¼å±€** - å…³æ³¨OpenAIã€Googleã€Anthropicç­‰å¤´éƒ¨ç©å®¶åŠ¨æ€
2. **å›½äº§ç®—åŠ›çªç ´** - èŠ¯ç‰‡è‡ªä¸»å¯æ§è¿›ç¨‹å€¼å¾—æŒç»­è·Ÿè¸ª
3. **åº”ç”¨è½åœ°è¿›å±•** - AIåº”ç”¨å•†ä¸šåŒ–è¿›å…¥å…³é”®æœŸ
4. **èµ„æœ¬æµå‘å˜åŒ–** - æŠ•èµ„çƒ­ç‚¹å¯èƒ½é¢„ç¤ºä¸‹ä¸€æ³¢é£å£

---

## äº”ã€æ•°æ®æ¥æº

æœ¬æŠ¥å‘Šæ•°æ®æ¥æºäºï¼š
"""
    
    sources = set(a.get("source", "") for a in top_articles)
    for source in sources:
        report += f"- {source}\n"
    
    report += f"""

---

*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}*  
*ç”± Tech News Aggregator è‡ªåŠ¨ç”Ÿæˆ*
"""
    
    return report

def main():
    """ä¸»å‡½æ•°"""
    print(f"[{datetime.now().isoformat()}] å¼€å§‹ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
    
    # åŠ è½½æ•°æ®
    data = load_processed_data()
    
    if not data:
        print("é”™è¯¯: æœªæ‰¾åˆ°å¤„ç†åçš„æ•°æ®")
        return
    
    # ç”ŸæˆæŠ¥å‘Š
    summary = generate_summary(data)
    detailed = generate_detailed_report(data)
    
    # ä¿å­˜æŠ¥å‘Š
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    date = data.get("date", datetime.now().strftime("%Y-%m-%d"))
    
    # æŒ‰æ—¶é—´åˆ†ç±»ä¿å­˜
    year_month = date[:7]  # 2026-02
    day_dir = OUTPUT_DIR / year_month
    day_dir.mkdir(parents=True, exist_ok=True)
    
    # ä¿å­˜æ‘˜è¦
    summary_file = day_dir / f"summary_{date}.md"
    with open(summary_file, "w", encoding="utf-8") as f:
        f.write(summary)
    print(f"æ‘˜è¦å·²ä¿å­˜: {summary_file}")
    
    # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
    detailed_file = day_dir / f"detailed_{date}.md"
    with open(detailed_file, "w", encoding="utf-8") as f:
        f.write(detailed)
    print(f"è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {detailed_file}")
    
    # ä¿å­˜å®Œæ•´JSON
    json_file = day_dir / f"report_{date}.json"
    report_data = {
        "date": date,
        "generated_at": datetime.now().isoformat(),
        "summary": summary,
        "detailed_report": detailed,
        "stats": {
            "total_articles": data.get("total_articles", 0),
            "categories": data.get("categories", {})
        }
    }
    with open(json_file, "w", encoding="utf-8") as f:
        json.dump(report_data, f, ensure_ascii=False, indent=2)
    
    print(f"\næŠ¥å‘Šç”Ÿæˆå®Œæˆ!")
    
    return report_data

if __name__ == "__main__":
    main()